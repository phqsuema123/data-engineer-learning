{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"tags": [],
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.7 \n",
					"output_type": "stream"
				},
				{
					"output_type": "display_data",
					"data": {
						"text/markdown": "\n# Available Magic Commands\n\n## Sessions Magic\n\n----\n    %help                             Return a list of descriptions and input types for all magic commands. \n    %profile            String        Specify a profile in your aws configuration to use as the credentials provider.\n    %region             String        Specify the AWS region in which to initialize a session. \n                                      Default from ~/.aws/config on Linux or macOS, \n                                      or C:\\Users\\ USERNAME \\.aws\\config\" on Windows.\n    %idle_timeout       Int           The number of minutes of inactivity after which a session will timeout. \n                                      Default: 2880 minutes (48 hours).\n    %timeout            Int           The number of minutes after which a session will timeout. \n                                      Default: 2880 minutes (48 hours).\n    %session_id_prefix  String        Define a String that will precede all session IDs in the format \n                                      [session_id_prefix]-[session_id]. If a session ID is not provided,\n                                      a random UUID will be generated.\n    %status                           Returns the status of the current Glue session including its duration, \n                                      configuration and executing user / role.\n    %session_id                       Returns the session ID for the running session.\n    %list_sessions                    Lists all currently running sessions by ID.\n    %stop_session                     Stops the current session.\n    %glue_version       String        The version of Glue to be used by this session. \n                                      Currently, the only valid options are 2.0, 3.0 and 4.0. \n                                      Default: 2.0.\n    %reconnect          String        Specify a live session ID to switch/reconnect to the sessions.\n----\n\n## Selecting Session Types\n\n----\n    %streaming          String        Sets the session type to Glue Streaming.\n    %etl                String        Sets the session type to Glue ETL.\n    %session_type       String        Specify a session_type to be used. Supported values: streaming and etl.\n----\n\n## Glue Config Magic \n*(common across all session types)*\n\n----\n\n    %%configure         Dictionary    A json-formatted dictionary consisting of all configuration parameters for \n                                      a session. Each parameter can be specified here or through individual magics.\n    %iam_role           String        Specify an IAM role ARN to execute your session with.\n                                      Default from ~/.aws/config on Linux or macOS, \n                                      or C:\\Users\\%USERNAME%\\.aws\\config` on Windows.\n    %number_of_workers  int           The number of workers of a defined worker_type that are allocated \n                                      when a session runs.\n                                      Default: 5.\n    %additional_python_modules  List  Comma separated list of additional Python modules to include in your cluster \n                                      (can be from Pypi or S3).\n    %%tags        Dictionary          Specify a json-formatted dictionary consisting of tags to use in the session.\n    \n    %%assume_role Dictionary, String  Specify a json-formatted dictionary or an IAM role ARN string to create a session \n                                      for cross account access.\n                                      E.g. {valid arn}\n                                      %%assume_role \n                                      'arn:aws:iam::XXXXXXXXXXXX:role/AWSGlueServiceRole' \n                                      E.g. {credentials}\n                                      %%assume_role\n                                      {\n                                            \"aws_access_key_id\" : \"XXXXXXXXXXXX\",\n                                            \"aws_secret_access_key\" : \"XXXXXXXXXXXX\",\n                                            \"aws_session_token\" : \"XXXXXXXXXXXX\"\n                                       }\n----\n\n                                      \n## Magic for Spark Sessions (ETL & Streaming)\n\n----\n    %worker_type        String        Set the type of instances the session will use as workers. \n    %connections        List          Specify a comma separated list of connections to use in the session.\n    %extra_py_files     List          Comma separated list of additional Python files From S3.\n    %extra_jars         List          Comma separated list of additional Jars to include in the cluster.\n    %spark_conf         String        Specify custom spark configurations for your session. \n                                      E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer\n----\n\n## Action Magic\n\n----\n\n    %%sql               String        Run SQL code. All lines after the initial %%sql magic will be passed\n                                      as part of the SQL code.  \n    %matplot      Matplotlib figure   Visualize your data using the matplotlib library.\n                                      E.g. \n                                      import matplotlib.pyplot as plt\n                                      # Set X-axis and Y-axis values\n                                      x = [5, 2, 8, 4, 9]\n                                      y = [10, 4, 8, 5, 2]\n                                      # Create a bar chart \n                                      plt.bar(x, y) \n                                      # Show the plot\n                                      %matplot plt    \n    %plotly            Plotly figure  Visualize your data using the plotly library.\n                                      E.g.\n                                      import plotly.express as px\n                                      #Create a graphical figure\n                                      fig = px.line(x=[\"a\",\"b\",\"c\"], y=[1,3,2], title=\"sample figure\")\n                                      #Show the figure\n                                      %plotly fig\n\n  \n                \n----\n\n"
					},
					"metadata": {}
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 3.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Current idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 3.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nIdle Timeout: 2880\nSession ID: 06629da6-1ff0-475e-891e-f1b26e75479b\nApplying the following default arguments:\n--glue_kernel_version 1.0.7\n--enable-glue-datacatalog true\nWaiting for session 06629da6-1ff0-475e-891e-f1b26e75479b to get into ready status...\nSession 06629da6-1ff0-475e-891e-f1b26e75479b has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "# 1. Extracting Data",
			"metadata": {
				"editable": true,
				"tags": [],
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "## 1.1 Extracting data from APIs (e.g., REST API)",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "import requests\nimport json\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, ArrayType\n\n# Fetch the JSON response using requests library\nresponse = requests.get(\"https://dummyjson.com/products/1\")\ndata = response.json()\nprint(data)\nschema = StructType([\n    StructField(\"id\", IntegerType(), nullable=False),\n    StructField(\"title\", StringType(), nullable=True),\n    StructField(\"description\", StringType(), nullable=True),\n     StructField(\"price\", FloatType(), nullable=True),\n    StructField(\"discountPercentage\", FloatType(), nullable=True),\n    StructField(\"rating\", FloatType(), nullable=True),\n    StructField(\"stock\", IntegerType(), nullable=True),\n    StructField(\"brand\", StringType(), nullable=True),\n    StructField(\"category\", StringType(), nullable=True),\n    StructField(\"thumbnail\", StringType(), nullable=True),\n    StructField(\"images\", ArrayType(StringType()), nullable=True)\n])\ndataframe = spark.createDataFrame([data], schema=schema)\n\n# Display the DataFrame\ndataframe.show()\n",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "{'id': 1, 'title': 'Essence Mascara Lash Princess', 'description': 'The Essence Mascara Lash Princess is a popular mascara known for its volumizing and lengthening effects. Achieve dramatic lashes with this long-lasting and cruelty-free formula.', 'category': 'beauty', 'price': 9.99, 'discountPercentage': 10.48, 'rating': 2.56, 'stock': 99, 'tags': ['beauty', 'mascara'], 'brand': 'Essence', 'sku': 'BEA-ESS-ESS-001', 'weight': 4, 'dimensions': {'width': 15.14, 'height': 13.08, 'depth': 22.99}, 'warrantyInformation': '1 week warranty', 'shippingInformation': 'Ships in 3-5 business days', 'availabilityStatus': 'In Stock', 'reviews': [{'rating': 3, 'comment': 'Would not recommend!', 'date': '2025-04-30T09:41:02.053Z', 'reviewerName': 'Eleanor Collins', 'reviewerEmail': 'eleanor.collins@x.dummyjson.com'}, {'rating': 4, 'comment': 'Very satisfied!', 'date': '2025-04-30T09:41:02.053Z', 'reviewerName': 'Lucas Gordon', 'reviewerEmail': 'lucas.gordon@x.dummyjson.com'}, {'rating': 5, 'comment': 'Highly impressed!', 'date': '2025-04-30T09:41:02.053Z', 'reviewerName': 'Eleanor Collins', 'reviewerEmail': 'eleanor.collins@x.dummyjson.com'}], 'returnPolicy': 'No return policy', 'minimumOrderQuantity': 48, 'meta': {'createdAt': '2025-04-30T09:41:02.053Z', 'updatedAt': '2025-04-30T09:41:02.053Z', 'barcode': '5784719087687', 'qrCode': 'https://cdn.dummyjson.com/public/qr-code.png'}, 'images': ['https://cdn.dummyjson.com/product-images/beauty/essence-mascara-lash-princess/1.webp'], 'thumbnail': 'https://cdn.dummyjson.com/product-images/beauty/essence-mascara-lash-princess/thumbnail.webp'}\n+---+--------------------+--------------------+-----+------------------+------+-----+-------+--------+--------------------+--------------------+\n| id|               title|         description|price|discountPercentage|rating|stock|  brand|category|           thumbnail|              images|\n+---+--------------------+--------------------+-----+------------------+------+-----+-------+--------+--------------------+--------------------+\n|  1|Essence Mascara L...|The Essence Masca...| 9.99|             10.48|  2.56|   99|Essence|  beauty|https://cdn.dummy...|[https://cdn.dumm...|\n+---+--------------------+--------------------+-----+------------------+------+-----+-------+--------+--------------------+--------------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## 1.2 Extracting data from files (e.g., CSV)",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "df_orders = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3://ndmphs-pyspark/landing_zone/orders/19980505\")\ndf_categories = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3://ndmphs-pyspark/landing_zone/categories\")\ndf_customers = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3://ndmphs-pyspark/landing_zone/customers\")\ndf_orders_details = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3://ndmphs-pyspark/landing_zone/orders_details\")\ndf_products = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3://ndmphs-pyspark/landing_zone/products\")\ndf_suppliers = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3://ndmphs-pyspark/landing_zone/suppliers\")\n\n# Display the DataFrame\ndf_products.show()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---------+--------------------+----------+----------+--------------------+---------+------------+------------+------------+------------+\n|productid|         productname|supplierid|categoryid|     quantityperunit|unitprice|unitsinstock|unitsonorder|reorderlevel|discontinued|\n+---------+--------------------+----------+----------+--------------------+---------+------------+------------+------------+------------+\n|        1|                Chai|         8|         1|  10 boxes x 30 bags|       18|          39|           0|          10|           1|\n|        2|               Chang|         1|         1|  24 - 12 oz bottles|       19|          17|          40|          25|           1|\n|        3|       Aniseed Syrup|         1|         2| 12 - 550 ml bottles|       10|          13|          70|          25|           0|\n|        4|Chef Anton's Caju...|         2|         2|      48 - 6 oz jars|       22|          53|           0|           0|           0|\n|        5|Chef Anton's Gumb...|         2|         2|            36 boxes|    21.35|           0|           0|           0|           1|\n|        6|Grandma's Boysenb...|         3|         2|      12 - 8 oz jars|       25|         120|           0|          25|           0|\n|        7|Uncle Bob's Organ...|         3|         7|     12 - 1 lb pkgs.|       30|          15|           0|          10|           0|\n|        8|Northwoods Cranbe...|         3|         2|     12 - 12 oz jars|       40|           6|           0|           0|           0|\n|        9|     Mishi Kobe Niku|         4|         6|    18 - 500 g pkgs.|       97|          29|           0|           0|           1|\n|       10|               Ikura|         4|         8|    12 - 200 ml jars|       31|          31|           0|           0|           0|\n|       11|      Queso Cabrales|         5|         4|           1 kg pkg.|       21|          22|          30|          30|           0|\n|       12|Queso Manchego La...|         5|         4|    10 - 500 g pkgs.|       38|          86|           0|           0|           0|\n|       13|               Konbu|         6|         8|            2 kg box|        6|          24|           0|           5|           0|\n|       14|                Tofu|         6|         7|    40 - 100 g pkgs.|    23.25|          35|           0|           0|           0|\n|       15|        Genen Shouyu|         6|         2| 24 - 250 ml bottles|       13|          39|           0|           5|           0|\n|       16|             Pavlova|         7|         3|    32 - 500 g boxes|    17.45|          29|           0|          10|           0|\n|       17|        Alice Mutton|         7|         6|      20 - 1 kg tins|       39|           0|           0|           0|           1|\n|       18|    Carnarvon Tigers|         7|         8|          16 kg pkg.|     62.5|          42|           0|           0|           0|\n|       19|Teatime Chocolate...|         8|         3|10 boxes x 12 pieces|      9.2|          25|           0|           5|           0|\n|       20|Sir Rodney's Marm...|         8|         3|       30 gift boxes|       81|          40|           0|           0|           0|\n+---------+--------------------+----------+----------+--------------------+---------+------------+------------+------------+------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## 1.3 Extracting data from a database using JDBC connection",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "jdbc_url = \"jdbc:postgresql://<host>:<port>/<database>\"\ndb_properties = {\"user\": \"<username>\", \"password\": \"<password>\", \"driver\": \"org.postgresql.Driver\"}\ndataframe = spark.read.format(\"jdbc\").options(url=jdbc_url, **db_properties).load()\n",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "# 2. Loading Data",
			"metadata": {}
		},
		{
			"cell_type": "markdown",
			"source": "## 2.1 Loading Data to S3 Raw Zone",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.functions import year, month, dayofmonth, format_string\n\ndf_orders = df_orders.withColumn(\"year\", year(df_orders['orderdate']))\ndf_orders = df_orders.withColumn(\"month\", format_string(\"%02d\", month(df_orders['orderdate'])))\ndf_orders = df_orders.withColumn(\"day\", format_string(\"%02d\",dayofmonth(df_orders['orderdate'])))\n\n\n\ndf_orders.write.partitionBy(\"year\", \"month\", \"day\").parquet(\"s3://ndmphs-pyspark/raw_zone/orders/partitioned_data/\")\ndf_categories.write.parquet(\"s3://ndmphs-pyspark/raw_zone/categories/\")\ndf_customers.write.parquet(\"s3://ndmphs-pyspark/raw_zone/customers/\")\ndf_orders_details.write.parquet(\"s3://ndmphs-pyspark/raw_zone/orders_details/\")\ndf_products.write.parquet(\"s3://ndmphs-pyspark/raw_zone/products/\")\ndf_suppliers.write.parquet(\"s3://ndmphs-pyspark/raw_zone/suppliers/\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## 2.2 Create Athena Table to read data from Raw Zone",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "def generate_ddl(dataframe, table_name, db_name, zone):\n    ddl_statement = f\"CREATE EXTERNAL TABLE IF NOT EXISTS {db_name}.{table_name} (\\n\"\n    \n    for field in dataframe.schema.fields:\n        column_name = field.name\n        data_type = field.dataType.simpleString()\n        ddl_statement += f\"  {column_name} {data_type},\\n\"\n    \n    ddl_statement = ddl_statement.rstrip(\",\\n\")\n    ddl_statement += f\"\\n)\\nSTORED AS PARQUET\\nLOCATION 's3://ndmphs-pyspark/{zone}/{table_name}/'\"\n    \n\n    # Print the DDL statement\n    print(ddl_statement)\n                  \n    # Create Athena Table\n    spark.sql(ddl_statement)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "db_name = \"raw_zone\"\ngenerate_ddl(df_categories, \"categories\", db_name, \"raw_zone\")\ngenerate_ddl(df_customers, \"customers\", db_name, \"raw_zone\")\ngenerate_ddl(df_orders_details,\"orders_details\", db_name, \"raw_zone\")\ngenerate_ddl(df_products, \"products\", db_name, \"raw_zone\")\ngenerate_ddl(df_suppliers, \"suppliers\", db_name, \"raw_zone\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "CREATE EXTERNAL TABLE IF NOT EXISTS raw_zone.categories (\n  categoryid string,\n  categoryname string,\n  description string,\n  picture string\n)\nSTORED AS PARQUET\nLOCATION 's3://ndmphs-pyspark/raw_zone/categories/'\nCREATE EXTERNAL TABLE IF NOT EXISTS raw_zone.customers (\n  customerid string,\n  companyname string,\n  contactname string,\n  contacttitle string,\n  address string,\n  city string,\n  region string,\n  postalcode string,\n  country string,\n  phone string,\n  fax string\n)\nSTORED AS PARQUET\nLOCATION 's3://ndmphs-pyspark/raw_zone/customers/'\nCREATE EXTERNAL TABLE IF NOT EXISTS raw_zone.orders_details (\n  orderid string,\n  productid string,\n  unitprice string,\n  quantity string,\n  discount string\n)\nSTORED AS PARQUET\nLOCATION 's3://ndmphs-pyspark/raw_zone/orders_details/'\nCREATE EXTERNAL TABLE IF NOT EXISTS raw_zone.products (\n  productid string,\n  productname string,\n  supplierid string,\n  categoryid string,\n  quantityperunit string,\n  unitprice string,\n  unitsinstock string,\n  unitsonorder string,\n  reorderlevel string,\n  discontinued string\n)\nSTORED AS PARQUET\nLOCATION 's3://ndmphs-pyspark/raw_zone/products/'\nCREATE EXTERNAL TABLE IF NOT EXISTS raw_zone.suppliers (\n  supplierid string,\n  companyname string,\n  contactname string,\n  contacttitle string,\n  address string,\n  city string,\n  region string,\n  postalcode string,\n  country string,\n  phone string,\n  fax string,\n  homepage string\n)\nSTORED AS PARQUET\nLOCATION 's3://ndmphs-pyspark/raw_zone/suppliers/'\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def generate_ddl_with_partition(dataframe, table_name, db_name, zone):\n    ddl_statement = f\"CREATE EXTERNAL TABLE IF NOT EXISTS {db_name}.{table_name} (\\n\"\n    \n    for field in dataframe.schema.fields:\n        column_name = field.name\n        if column_name not in [\"year\", \"month\", \"day\"]:\n            data_type = field.dataType.simpleString()\n            ddl_statement += f\"  {column_name} {data_type},\\n\"\n    \n    ddl_statement = ddl_statement.rstrip(\",\\n\")\n    ddl_statement += f\"\"\"\\n)\n                        PARTITIONED BY ( \n                          `year` int, \n                          `month` int, \n                          `day` int)\n                        \"\"\"\n    ddl_statement += f\"\\nSTORED AS PARQUET\\nLOCATION 's3://ndmphs-pyspark/{zone}/{table_name}/partitioned_data/'\"\n    \n\n    # Print the DDL statement\n    print(ddl_statement)\n                  \n    # Create Athena Table\n    spark.sql(ddl_statement)\n    spark.sql(f\"MSCK REPAIR TABLE {db_name}.{table_name}\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "generate_ddl_with_partition(df_orders, \"orders\", db_name, \"raw_zone\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "CREATE EXTERNAL TABLE IF NOT EXISTS raw_zone.orders (\n  orderid string,\n  customerid string,\n  employeeid string,\n  orderdate string,\n  requireddate string,\n  shippeddate string,\n  shipvia string,\n  freight string,\n  shipname string,\n  shipaddress string,\n  shipcity string,\n  shipregion string,\n  shippostalcode string,\n  shipcountry string\n)\n                        PARTITIONED BY ( \n                          `year` int, \n                          `month` int, \n                          `day` int)\n                        \nSTORED AS PARQUET\nLOCATION 's3://ndmphs-pyspark/raw_zone/orders/partitioned_data/'\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "# 3. Transforming data",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Joining data\ndf_products = df_products.alias(\"products\")\ndf_categories = df_categories.alias(\"categories\")\ndf_suppliers = df_suppliers.alias(\"suppliers\")\n\ndf_dim_products = df_products \\\n                    .join(df_categories, df_products[\"categoryid\"] == df_categories[\"categoryid\"], how=\"right\").drop(*[\"categoryid\"]) \\\n                    .join(df_suppliers,df_products[\"supplierid\"] == df_suppliers[\"supplierid\"], how=\"right\").drop(*[\"supplierid\"])\ndf_dim_products.show()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---------+--------------------+-------------------+---------+------------+------------+------------+------------+--------------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-----------+--------+----------+---------+--------------+--------------+--------------------+\n|productid|         productname|    quantityperunit|unitprice|unitsinstock|unitsonorder|reorderlevel|discontinued|  categoryname|         description|picture|         companyname|         contactname|        contacttitle|             address|       city|  region|postalcode|  country|         phone|           fax|            homepage|\n+---------+--------------------+-------------------+---------+------------+------------+------------+------------+--------------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-----------+--------+----------+---------+--------------+--------------+--------------------+\n|        3|       Aniseed Syrup|12 - 550 ml bottles|       10|          13|          70|          25|           0|    Condiments|Sweet and savory ...|     \\x|      Exotic Liquids|    Charlotte Cooper|  Purchasing Manager|      49 Gilbert St.|     London|    null|   EC1 4SD|       UK|(171) 555-2222|          null|                null|\n|        2|               Chang| 24 - 12 oz bottles|       19|          17|          40|          25|           1|     Beverages|Soft drinks, coff...|     \\x|      Exotic Liquids|    Charlotte Cooper|  Purchasing Manager|      49 Gilbert St.|     London|    null|   EC1 4SD|       UK|(171) 555-2222|          null|                null|\n|       66|Louisiana Hot Spi...|     24 - 8 oz jars|       17|           4|         100|          20|           0|    Condiments|Sweet and savory ...|     \\x|New Orleans Cajun...|       Shelley Burke| Order Administrator|      P.O. Box 78934|New Orleans|      LA|     70117|      USA|(100) 555-4822|          null|         #CAJUN.HTM#|\n|       65|Louisiana Fiery H...|  32 - 8 oz bottles|    21.05|          76|           0|           0|           0|    Condiments|Sweet and savory ...|     \\x|New Orleans Cajun...|       Shelley Burke| Order Administrator|      P.O. Box 78934|New Orleans|      LA|     70117|      USA|(100) 555-4822|          null|         #CAJUN.HTM#|\n|        5|Chef Anton's Gumb...|           36 boxes|    21.35|           0|           0|           0|           1|    Condiments|Sweet and savory ...|     \\x|New Orleans Cajun...|       Shelley Burke| Order Administrator|      P.O. Box 78934|New Orleans|      LA|     70117|      USA|(100) 555-4822|          null|         #CAJUN.HTM#|\n|        4|Chef Anton's Caju...|     48 - 6 oz jars|       22|          53|           0|           0|           0|    Condiments|Sweet and savory ...|     \\x|New Orleans Cajun...|       Shelley Burke| Order Administrator|      P.O. Box 78934|New Orleans|      LA|     70117|      USA|(100) 555-4822|          null|         #CAJUN.HTM#|\n|        8|Northwoods Cranbe...|    12 - 12 oz jars|       40|           6|           0|           0|           0|    Condiments|Sweet and savory ...|     \\x|Grandma Kelly's H...|       Regina Murphy|Sales Representative|      707 Oxford Rd.|  Ann Arbor|      MI|     48104|      USA|(313) 555-5735|(313) 555-3349|                null|\n|        7|Uncle Bob's Organ...|    12 - 1 lb pkgs.|       30|          15|           0|          10|           0|       Produce|Dried fruit and b...|     \\x|Grandma Kelly's H...|       Regina Murphy|Sales Representative|      707 Oxford Rd.|  Ann Arbor|      MI|     48104|      USA|(313) 555-5735|(313) 555-3349|                null|\n|        6|Grandma's Boysenb...|     12 - 8 oz jars|       25|         120|           0|          25|           0|    Condiments|Sweet and savory ...|     \\x|Grandma Kelly's H...|       Regina Murphy|Sales Representative|      707 Oxford Rd.|  Ann Arbor|      MI|     48104|      USA|(313) 555-5735|(313) 555-3349|                null|\n|       74|       Longlife Tofu|          5 kg pkg.|       10|           4|          20|           5|           0|       Produce|Dried fruit and b...|     \\x|       Tokyo Traders|        Yoshi Nagase|   Marketing Manager|9-8 Sekimai Musas...|      Tokyo|    null|       100|    Japan|(03) 3555-5011|          null|                null|\n|       10|               Ikura|   12 - 200 ml jars|       31|          31|           0|           0|           0|       Seafood|    Seaweed and fish|     \\x|       Tokyo Traders|        Yoshi Nagase|   Marketing Manager|9-8 Sekimai Musas...|      Tokyo|    null|       100|    Japan|(03) 3555-5011|          null|                null|\n|        9|     Mishi Kobe Niku|   18 - 500 g pkgs.|       97|          29|           0|           0|           1|  Meat/Poultry|      Prepared meats|     \\x|       Tokyo Traders|        Yoshi Nagase|   Marketing Manager|9-8 Sekimai Musas...|      Tokyo|    null|       100|    Japan|(03) 3555-5011|          null|                null|\n|       12|Queso Manchego La...|   10 - 500 g pkgs.|       38|          86|           0|           0|           0|Dairy Products|             Cheeses|     \\x|Cooperativa de Qu...|Antonio del Valle...|Export Administrator|   Calle del Rosal 4|     Oviedo|Asturias|     33007|    Spain|(98) 598 76 54|          null|                null|\n|       11|      Queso Cabrales|          1 kg pkg.|       21|          22|          30|          30|           0|Dairy Products|             Cheeses|     \\x|Cooperativa de Qu...|Antonio del Valle...|Export Administrator|   Calle del Rosal 4|     Oviedo|Asturias|     33007|    Spain|(98) 598 76 54|          null|                null|\n|       15|        Genen Shouyu|24 - 250 ml bottles|       13|          39|           0|           5|           0|    Condiments|Sweet and savory ...|     \\x|            Mayumi's|         Mayumi Ohno|Marketing Represe...|  92 Setsuko Chuo-ku|      Osaka|    null|       545|    Japan| (06) 431-7877|          null|Mayumi's (on the ...|\n|       14|                Tofu|   40 - 100 g pkgs.|    23.25|          35|           0|           0|           0|       Produce|Dried fruit and b...|     \\x|            Mayumi's|         Mayumi Ohno|Marketing Represe...|  92 Setsuko Chuo-ku|      Osaka|    null|       545|    Japan| (06) 431-7877|          null|Mayumi's (on the ...|\n|       13|               Konbu|           2 kg box|        6|          24|           0|           5|           0|       Seafood|    Seaweed and fish|     \\x|            Mayumi's|         Mayumi Ohno|Marketing Represe...|  92 Setsuko Chuo-ku|      Osaka|    null|       545|    Japan| (06) 431-7877|          null|Mayumi's (on the ...|\n|       70|       Outback Lager|24 - 355 ml bottles|       15|          15|          10|          30|           0|     Beverages|Soft drinks, coff...|     \\x|       Pavlova, Ltd.|         Ian Devling|   Marketing Manager|74 Rose St. Mooni...|  Melbourne|Victoria|      3058|Australia| (03) 444-2343| (03) 444-6588|                null|\n|       63|        Vegie-spread|    15 - 625 g jars|     43.9|          24|           0|           5|           0|    Condiments|Sweet and savory ...|     \\x|       Pavlova, Ltd.|         Ian Devling|   Marketing Manager|74 Rose St. Mooni...|  Melbourne|Victoria|      3058|Australia| (03) 444-2343| (03) 444-6588|                null|\n|       18|    Carnarvon Tigers|         16 kg pkg.|     62.5|          42|           0|           0|           0|       Seafood|    Seaweed and fish|     \\x|       Pavlova, Ltd.|         Ian Devling|   Marketing Manager|74 Rose St. Mooni...|  Melbourne|Victoria|      3058|Australia| (03) 444-2343| (03) 444-6588|                null|\n+---------+--------------------+-------------------+---------+------------+------------+------------+------------+--------------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-----------+--------+----------+---------+--------------+--------------+--------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "\ndf_orders_details = df_orders_details.withColumnRenamed(\"orderid\", \"orderid_2\")\ndf_fact_orders_items = df_orders_details  \\\n                    .join(df_orders, df_orders[\"orderid\"] == df_orders_details[\"orderid_2\"], how=\"right\").drop(*[\"orderid_2\"])\ndf_fact_orders_items.show()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---------+---------+--------+--------+-------+----------+----------+----------+------------+-----------+-------+-------+--------------------+--------------------+--------------+----------+--------------+-----------+----+-----+---+\n|productid|unitprice|quantity|discount|orderid|customerid|employeeid| orderdate|requireddate|shippeddate|shipvia|freight|            shipname|         shipaddress|      shipcity|shipregion|shippostalcode|shipcountry|year|month|day|\n+---------+---------+--------+--------+-------+----------+----------+----------+------------+-----------+-------+-------+--------------------+--------------------+--------------+----------+--------------+-----------+----+-----+---+\n|       72|     34.8|       5|       0|  10248|     VINET|         5|1996-07-04|  1996-08-01| 1996-07-16|      3|  32.38|Vins et alcools C...|  59 rue de l'Abbaye|         Reims|      null|         51100|     France|1996|   07| 04|\n|       42|      9.8|      10|       0|  10248|     VINET|         5|1996-07-04|  1996-08-01| 1996-07-16|      3|  32.38|Vins et alcools C...|  59 rue de l'Abbaye|         Reims|      null|         51100|     France|1996|   07| 04|\n|       11|       14|      12|       0|  10248|     VINET|         5|1996-07-04|  1996-08-01| 1996-07-16|      3|  32.38|Vins et alcools C...|  59 rue de l'Abbaye|         Reims|      null|         51100|     France|1996|   07| 04|\n|       51|     42.4|      40|       0|  10249|     TOMSP|         6|1996-07-05|  1996-08-16| 1996-07-10|      1|  11.61|  Toms Spezialitäten|       Luisenstr. 48|       Münster|      null|         44087|    Germany|1996|   07| 05|\n|       14|     18.6|       9|       0|  10249|     TOMSP|         6|1996-07-05|  1996-08-16| 1996-07-10|      1|  11.61|  Toms Spezialitäten|       Luisenstr. 48|       Münster|      null|         44087|    Germany|1996|   07| 05|\n|       65|     16.8|      15|    0.15|  10250|     HANAR|         4|1996-07-08|  1996-08-05| 1996-07-12|      2|  65.83|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 08|\n|       51|     42.4|      35|    0.15|  10250|     HANAR|         4|1996-07-08|  1996-08-05| 1996-07-12|      2|  65.83|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 08|\n|       41|      7.7|      10|       0|  10250|     HANAR|         4|1996-07-08|  1996-08-05| 1996-07-12|      2|  65.83|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 08|\n|       65|     16.8|      20|       0|  10251|     VICTE|         3|1996-07-08|  1996-08-05| 1996-07-15|      1|  41.34|Victuailles en stock|  2, rue du Commerce|          Lyon|      null|         69004|     France|1996|   07| 08|\n|       57|     15.6|      15|    0.05|  10251|     VICTE|         3|1996-07-08|  1996-08-05| 1996-07-15|      1|  41.34|Victuailles en stock|  2, rue du Commerce|          Lyon|      null|         69004|     France|1996|   07| 08|\n|       22|     16.8|       6|    0.05|  10251|     VICTE|         3|1996-07-08|  1996-08-05| 1996-07-15|      1|  41.34|Victuailles en stock|  2, rue du Commerce|          Lyon|      null|         69004|     France|1996|   07| 08|\n|       60|     27.2|      40|       0|  10252|     SUPRD|         4|1996-07-09|  1996-08-06| 1996-07-11|      2|   51.3|    Suprêmes délices|Boulevard Tirou, 255|     Charleroi|      null|        B-6000|    Belgium|1996|   07| 09|\n|       33|        2|      25|    0.05|  10252|     SUPRD|         4|1996-07-09|  1996-08-06| 1996-07-11|      2|   51.3|    Suprêmes délices|Boulevard Tirou, 255|     Charleroi|      null|        B-6000|    Belgium|1996|   07| 09|\n|       20|     64.8|      40|    0.05|  10252|     SUPRD|         4|1996-07-09|  1996-08-06| 1996-07-11|      2|   51.3|    Suprêmes délices|Boulevard Tirou, 255|     Charleroi|      null|        B-6000|    Belgium|1996|   07| 09|\n|       49|       16|      40|       0|  10253|     HANAR|         3|1996-07-10|  1996-07-24| 1996-07-16|      2|  58.17|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 10|\n|       39|     14.4|      42|       0|  10253|     HANAR|         3|1996-07-10|  1996-07-24| 1996-07-16|      2|  58.17|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 10|\n|       31|       10|      20|       0|  10253|     HANAR|         3|1996-07-10|  1996-07-24| 1996-07-16|      2|  58.17|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 10|\n|       74|        8|      21|       0|  10254|     CHOPS|         5|1996-07-11|  1996-08-08| 1996-07-23|      2|  22.98|   Chop-suey Chinese|        Hauptstr. 31|          Bern|      null|          3012|Switzerland|1996|   07| 11|\n|       55|     19.2|      21|    0.15|  10254|     CHOPS|         5|1996-07-11|  1996-08-08| 1996-07-23|      2|  22.98|   Chop-suey Chinese|        Hauptstr. 31|          Bern|      null|          3012|Switzerland|1996|   07| 11|\n|       24|      3.6|      15|    0.15|  10254|     CHOPS|         5|1996-07-11|  1996-08-08| 1996-07-23|      2|  22.98|   Chop-suey Chinese|        Hauptstr. 31|          Bern|      null|          3012|Switzerland|1996|   07| 11|\n+---------+---------+--------+--------+-------+----------+----------+----------+------------+-----------+-------+-------+--------------------+--------------------+--------------+----------+--------------+-----------+----+-----+---+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "## 3.1 Trasnform Fact_Orders_Items",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.functions import expr, concat, substring, col, to_date\n# Add 543 years to the orderdate column while maintaining month-day format\ndf_fact_orders_items = df_fact_orders_items.withColumn(\"new_year\", expr(\"substring(orderdate, 1, 4) + 543\"))\ndf_fact_orders_items = df_fact_orders_items.withColumn(\"orderdate\", expr(\"concat(cast(substring(orderdate, 1, 4) + 543 as string), substring(orderdate, 5))\"))\ndf_fact_orders_items = df_fact_orders_items.withColumn(\"orderdate\", expr(\"replace(cast(orderdate as string), '.0', '')\"))\ndf_fact_orders_items = df_fact_orders_items.withColumn(\"orderdate\", to_date(\"orderdate\", \"yyyy-MM-dd\"))\n\ndf_fact_orders_items.show()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 16,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---------+---------+--------+--------+-------+----------+----------+----------+------------+-----------+-------+-------+--------------------+--------------------+--------------+----------+--------------+-----------+----+-----+---+--------+\n|productid|unitprice|quantity|discount|orderid|customerid|employeeid| orderdate|requireddate|shippeddate|shipvia|freight|            shipname|         shipaddress|      shipcity|shipregion|shippostalcode|shipcountry|year|month|day|new_year|\n+---------+---------+--------+--------+-------+----------+----------+----------+------------+-----------+-------+-------+--------------------+--------------------+--------------+----------+--------------+-----------+----+-----+---+--------+\n|       72|     34.8|       5|       0|  10248|     VINET|         5|2539-07-04|  1996-08-01| 1996-07-16|      3|  32.38|Vins et alcools C...|  59 rue de l'Abbaye|         Reims|      null|         51100|     France|1996|   07| 04|  2539.0|\n|       42|      9.8|      10|       0|  10248|     VINET|         5|2539-07-04|  1996-08-01| 1996-07-16|      3|  32.38|Vins et alcools C...|  59 rue de l'Abbaye|         Reims|      null|         51100|     France|1996|   07| 04|  2539.0|\n|       11|       14|      12|       0|  10248|     VINET|         5|2539-07-04|  1996-08-01| 1996-07-16|      3|  32.38|Vins et alcools C...|  59 rue de l'Abbaye|         Reims|      null|         51100|     France|1996|   07| 04|  2539.0|\n|       51|     42.4|      40|       0|  10249|     TOMSP|         6|2539-07-05|  1996-08-16| 1996-07-10|      1|  11.61|  Toms Spezialitäten|       Luisenstr. 48|       Münster|      null|         44087|    Germany|1996|   07| 05|  2539.0|\n|       14|     18.6|       9|       0|  10249|     TOMSP|         6|2539-07-05|  1996-08-16| 1996-07-10|      1|  11.61|  Toms Spezialitäten|       Luisenstr. 48|       Münster|      null|         44087|    Germany|1996|   07| 05|  2539.0|\n|       65|     16.8|      15|    0.15|  10250|     HANAR|         4|2539-07-08|  1996-08-05| 1996-07-12|      2|  65.83|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 08|  2539.0|\n|       51|     42.4|      35|    0.15|  10250|     HANAR|         4|2539-07-08|  1996-08-05| 1996-07-12|      2|  65.83|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 08|  2539.0|\n|       41|      7.7|      10|       0|  10250|     HANAR|         4|2539-07-08|  1996-08-05| 1996-07-12|      2|  65.83|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 08|  2539.0|\n|       65|     16.8|      20|       0|  10251|     VICTE|         3|2539-07-08|  1996-08-05| 1996-07-15|      1|  41.34|Victuailles en stock|  2, rue du Commerce|          Lyon|      null|         69004|     France|1996|   07| 08|  2539.0|\n|       57|     15.6|      15|    0.05|  10251|     VICTE|         3|2539-07-08|  1996-08-05| 1996-07-15|      1|  41.34|Victuailles en stock|  2, rue du Commerce|          Lyon|      null|         69004|     France|1996|   07| 08|  2539.0|\n|       22|     16.8|       6|    0.05|  10251|     VICTE|         3|2539-07-08|  1996-08-05| 1996-07-15|      1|  41.34|Victuailles en stock|  2, rue du Commerce|          Lyon|      null|         69004|     France|1996|   07| 08|  2539.0|\n|       60|     27.2|      40|       0|  10252|     SUPRD|         4|2539-07-09|  1996-08-06| 1996-07-11|      2|   51.3|    Suprêmes délices|Boulevard Tirou, 255|     Charleroi|      null|        B-6000|    Belgium|1996|   07| 09|  2539.0|\n|       33|        2|      25|    0.05|  10252|     SUPRD|         4|2539-07-09|  1996-08-06| 1996-07-11|      2|   51.3|    Suprêmes délices|Boulevard Tirou, 255|     Charleroi|      null|        B-6000|    Belgium|1996|   07| 09|  2539.0|\n|       20|     64.8|      40|    0.05|  10252|     SUPRD|         4|2539-07-09|  1996-08-06| 1996-07-11|      2|   51.3|    Suprêmes délices|Boulevard Tirou, 255|     Charleroi|      null|        B-6000|    Belgium|1996|   07| 09|  2539.0|\n|       49|       16|      40|       0|  10253|     HANAR|         3|2539-07-10|  1996-07-24| 1996-07-16|      2|  58.17|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 10|  2539.0|\n|       39|     14.4|      42|       0|  10253|     HANAR|         3|2539-07-10|  1996-07-24| 1996-07-16|      2|  58.17|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 10|  2539.0|\n|       31|       10|      20|       0|  10253|     HANAR|         3|2539-07-10|  1996-07-24| 1996-07-16|      2|  58.17|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|1996|   07| 10|  2539.0|\n|       74|        8|      21|       0|  10254|     CHOPS|         5|2539-07-11|  1996-08-08| 1996-07-23|      2|  22.98|   Chop-suey Chinese|        Hauptstr. 31|          Bern|      null|          3012|Switzerland|1996|   07| 11|  2539.0|\n|       55|     19.2|      21|    0.15|  10254|     CHOPS|         5|2539-07-11|  1996-08-08| 1996-07-23|      2|  22.98|   Chop-suey Chinese|        Hauptstr. 31|          Bern|      null|          3012|Switzerland|1996|   07| 11|  2539.0|\n|       24|      3.6|      15|    0.15|  10254|     CHOPS|         5|2539-07-11|  1996-08-08| 1996-07-23|      2|  22.98|   Chop-suey Chinese|        Hauptstr. 31|          Bern|      null|          3012|Switzerland|1996|   07| 11|  2539.0|\n+---------+---------+--------+--------+-------+----------+----------+----------+------------+-----------+-------+-------+--------------------+--------------------+--------------+----------+--------------+-----------+----+-----+---+--------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## 3.2 Load Transformed Data To Serving Zone",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df_fact_orders_items.drop(*[\"year\",\"month\",\"day\"])\ndf_fact_orders_items = df_fact_orders_items.withColumn(\"year\", year(df_fact_orders_items['orderdate']))\ndf_fact_orders_items = df_fact_orders_items.withColumn(\"month\", format_string(\"%02d\", month(df_fact_orders_items['orderdate'])))\ndf_fact_orders_items = df_fact_orders_items.withColumn(\"day\", format_string(\"%02d\",dayofmonth(df_fact_orders_items['orderdate'])))\n\ndf_fact_orders_items.write.partitionBy(\"year\", \"month\", \"day\").parquet(\"s3://ndmphs-pyspark/serving_zone/fact_orders_items/partitioned_data/\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_dim_products.write.parquet(\"s3://ndmphs-pyspark/serving_zone/dim_products/\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "db_name='serving_zone'\ngenerate_ddl(df_dim_products, \"dim_products\", db_name, \"serving_zone\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "CREATE EXTERNAL TABLE IF NOT EXISTS serving_zone.dim_products (\n  productid string,\n  productname string,\n  quantityperunit string,\n  unitprice string,\n  unitsinstock string,\n  unitsonorder string,\n  reorderlevel string,\n  discontinued string,\n  categoryname string,\n  description string,\n  picture string,\n  companyname string,\n  contactname string,\n  contacttitle string,\n  address string,\n  city string,\n  region string,\n  postalcode string,\n  country string,\n  phone string,\n  fax string,\n  homepage string\n)\nSTORED AS PARQUET\nLOCATION 's3://ndmphs-pyspark/serving_zone/dim_products/'\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "generate_ddl_with_partition(df_fact_orders_items, \"fact_orders_items\", db_name, \"serving_zone\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 23,
			"outputs": [
				{
					"name": "stdout",
					"text": "CREATE EXTERNAL TABLE IF NOT EXISTS serving_zone.fact_orders_items (\n  productid string,\n  unitprice string,\n  quantity string,\n  discount string,\n  orderid string,\n  customerid string,\n  employeeid string,\n  orderdate date,\n  requireddate string,\n  shippeddate string,\n  shipvia string,\n  freight string,\n  shipname string,\n  shipaddress string,\n  shipcity string,\n  shipregion string,\n  shippostalcode string,\n  shipcountry string,\n  new_year double\n)\n                        PARTITIONED BY ( \n                          `year` int, \n                          `month` int, \n                          `day` int)\n                        \nSTORED AS PARQUET\nLOCATION 's3://ndmphs-pyspark/serving_zone/fact_orders_items/partitioned_data/'\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}